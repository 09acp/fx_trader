{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning -  USD/EUR 40years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as sql\n",
    "import import_ipynb # pip install import-ipynb\n",
    "#from toolbox import * # helper functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Price Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7672, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-07</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-08</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price    Open    High     Low\n",
       "Date                                      \n",
       "1980-01-02  0.6601  0.6601  0.6601  0.6601\n",
       "1980-01-03  0.6589  0.6589  0.6589  0.6589\n",
       "1980-01-04  0.6610  0.6610  0.6610  0.6610\n",
       "1980-01-07  0.6593  0.6593  0.6593  0.6593\n",
       "1980-01-08  0.6619  0.6619  0.6619  0.6619"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "for f in range(1,4):\n",
    "    l.append(pd.read_csv(\"usd_eur_40yrs/%s.csv\"%(f),\n",
    "                     na_filter=True,\n",
    "                     parse_dates=True,\n",
    "                     index_col=\"Date\",\n",
    "                    ))\n",
    "# merge 10year csvs\n",
    "df = pd.concat(l,axis=0)\n",
    "# sort by date\n",
    "df.sort_values([\"Date\"],inplace=True)\n",
    "# needless feature\n",
    "df.drop(\"Change %\",axis=1,inplace=True)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to database\n",
    "conn = sql.connect('database.db')\n",
    "cur = conn.cursor()\n",
    "df.to_sql(\"raw_prices\", conn, if_exists=\"replace\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section for TA indicators (Future)\n",
    "\n",
    "- No volume in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GAF images\n",
    "- apply a 5day rolling window to create 1day step labels for supervised learning \n",
    "- independent variables for training set:  Open, High, Low\n",
    "- dependent variable: Price\n",
    "- 80-20 train/test split\n",
    "- **Just 2 classes B/S** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pyts.image import GramianAngularField # conda install -c conda-forge pyts\n",
    "\n",
    "# Parameters\n",
    "path = 'database.db'\n",
    "table_name = 'raw_prices'\n",
    "n_steps = 5 # 5 day rolling window \n",
    "split_threshold = 0.80 # 80-20 train-test split\n",
    "transaction_threshold = 1 # Transaction cost per trade as a % ( 1 = 1 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 t     t+1  class\n",
      "Date                             \n",
      "1980-01-02  0.6601  0.6601      1\n",
      "1980-01-03  0.6589  0.6601      1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve raw prices\n",
    "conn = sql.connect(path)\n",
    "cur = conn.cursor()\n",
    "df = pd.read_sql_query(\"SELECT Date,Price, Open, High, Low FROM %s\" %(table_name), conn)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index(['Date'],inplace=True)\n",
    "\n",
    "# Create labels for supervised learning\n",
    "df_classes = pd.DataFrame()\n",
    "df_classes[\"t\"] = df['Price']\n",
    "df_classes[\"t+1\"] = df['Price'].shift(1); df_classes[\"t+1\"][0] = 0.6601 # fill original val\n",
    "df_classes[\"class\"] = 0\n",
    "df_classes[\"class\"].where(df_classes[\"t\"].values>df_classes[\"t+1\"].values,\n",
    "                          1, # if price rise -> BUY , else -> SELL\n",
    "                          inplace=True,  )\n",
    "print(df_classes.head(2))\n",
    "# Save labels to database\n",
    "df_classes.to_sql(\"classes\", conn, if_exists=\"replace\")\n",
    "conn.close()\n",
    "\n",
    "# Set as new feature in df\n",
    "df['Class'] = df_classes[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980-01-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class\n",
       "Date             \n",
       "1980-01-02      1\n",
       "1980-01-09      1\n",
       "1980-01-16      1\n",
       "1980-01-23      1\n",
       "1980-01-30      1\n",
       "...           ...\n",
       "2009-12-03      1\n",
       "2009-12-10      1\n",
       "2009-12-17      0\n",
       "2009-12-24      1\n",
       "2009-12-31      0\n",
       "\n",
       "[1535 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame(df['Class'].iloc[::5]) # every 5th value is a label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7667, 5, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORKS but need to do on train / test sets - this is everything\n",
    "\n",
    "train_d = df.drop([\"Price\",\"Class\"],axis=1).to_numpy()\n",
    "l = []\n",
    "for i in range(len(train_d)):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + n_steps\n",
    "    # check if we are beyond the dataset\n",
    "    if end_ix > len(train_d)-1:\n",
    "        break\n",
    "    l.append(train_d[i:end_ix, :])\n",
    "np.array(l).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def split_time_series(dfx):\n",
    "            dfx_train = dfx.loc[:, dfx.columns != 'Price']\n",
    "            dfx_train = dfx_train.to_numpy()\n",
    "            dfx_labels = dfx['Price']\n",
    "            dfx_labels = dfx_labels.to_numpy()\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(dfx_train)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + self.n_steps\n",
    "                # check if we are beyond the dataset\n",
    "                if end_ix > len(dfx_train)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = dfx_train[i:end_ix, :], dfx_labels[end_ix] \n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pre_processing(df, n_steps , split_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "train_data, test_data = data.split_data()\n",
    "\n",
    "print(train_data.shape, test_data.shape )\n",
    "# TRANSFROM ALL FEATURES EXCEPT ADJCLOSE PRICES\n",
    "tranformed_train, transformed_test = scale_and_polarise(train_data.iloc[:,:-1],test_data.iloc[:,:-1])\n",
    "tranformed_train.columns, transformed_test.columns = train_data.drop(['Price'],axis=1).columns, test_data.drop(['Price'],axis=1).columns\n",
    "\n",
    "tranformed_train['Price'] = train_data.iloc[:,-1].values\n",
    "transformed_test['Price'] = test_data.iloc[:,-1].values\n",
    "\n",
    "tranformed_train.index, transformed_test.index = train_data.index, test_data.index\n",
    "tX, tY, vX, vY  = data.tensor_samples_labels(tranformed_train, transformed_test, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX.shape, vX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_polarise(train_data,test_data):\n",
    "    # def prep_data\n",
    "    \" Scale data between [ 0 , 1 ] with MinMax  \"\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler1 = MinMaxScaler()\n",
    "    scaler2 = MinMaxScaler()\n",
    "\n",
    "    scaled_train = scaler1.fit_transform(train_data)\n",
    "    scaled_test= scaler2.fit_transform(test_data)\n",
    "    #print(np.max(scaled_train) , np.max(scaled_test)) # sanity check\n",
    "\n",
    "    \" Encode angles as Polar Coordinates  \"\n",
    "    polar_train = np.arccos(scaled_train)\n",
    "    polar_test = np.arccos(scaled_test)\n",
    "    #print(np.max(polar_train) , np.max(polar_test)) # sanity check\n",
    "\n",
    "    return pd.DataFrame(polar_train), pd.DataFrame(polar_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processing ():\n",
    "    def __init__(self, df, n_steps , split_threshold):\n",
    "        self.df = df\n",
    "        self.n_steps = n_steps # the size of the sliding window\n",
    "        self.split_threshold = split_threshold  # the ratio for the train:test split\n",
    "        self.df_train = None\n",
    "        self.df_test = None\n",
    "    def split_data(self):\n",
    "        # 80 - 20 data split \n",
    "        self.df_train = self.df.iloc[ : int(len(self.df)*split_threshold), : ]\n",
    "        self.df_test = self.df.iloc[ int(len(self.df)*split_threshold):, : ]         \n",
    "        return self.df_train, self.df_test        \n",
    "    def tensor_samples_labels (self,df_train,df_test,table):\n",
    "        # create training data and labels for the time_series\n",
    "        def split_time_series(dfx):\n",
    "            dfx_train = dfx.loc[:, dfx.columns != 'Price']\n",
    "            dfx_train = dfx_train.to_numpy()\n",
    "            dfx_labels = dfx['Price']\n",
    "            dfx_labels = dfx_labels.to_numpy()\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(dfx_train)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + self.n_steps\n",
    "                # check if we are beyond the dataset\n",
    "                if end_ix > len(dfx_train)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = dfx_train[i:end_ix, :], dfx_labels[end_ix] \n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return np.array(X), np.array(y) \n",
    "        # convert into input/output\n",
    "        train_X, train_Y = split_time_series(df_train)\n",
    "        val_X, val_Y = split_time_series(df_test)\n",
    "        return train_X, train_Y , val_X, val_Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
